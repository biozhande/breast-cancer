---
title: "Breast Cancer Analysis"
author: "Rachel Zhande"
date: "12/12/2019"
output:
  pdf_document: default
  html_document: default
---
knitr::opts_chunk$set(
    message = FALSE,
    warning = FALSE
)

# 1. Introduction
## The Dataset and Problem Statement
The Breast Cancer (Wisconsin) Diagnosis dataset contains the diagnosis and a set of 30 features describing the characteristics of the cell nuclei present in a biopsy of a breast mass.
Ten real attributes were computed for each patient (ie. measured observable attributes from images that were taken for each patient):

1. radius (mean of distances from center to points on the perimeter);
2. texture (standard deviation of gray-scale values);
3. perimeter;
4. area;
5. smoothness (local variation in radius lengths);
6. compactness (perimeter^2 / area - 1.0);
7. concavity (severity of concave portions of the contour);
8. concave points (number of concave portions of the contour);
9. symmetry;
10. fractal dimension (“coastline approximation” - 1).

The rest are essentially derived values for the ten real-valued features above ie standard error (SE) and “worst” or largest (mean of the three largest values), resulting in 30 features. We will analyze the features to understand ther predictive value for diagnosis. We will then create models using two different algorithms and use the models to predict the diagnosis.

The dataset is available on the [UCI Machine learning website](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29) as well as on [Kaggle](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data).

# 2. Load Libraries and Dataset 

```{r Libraries, warning=FALSE}
library(ggplot2)
library(dplyr)
library(tidyverse)
library(caret)
library(ggthemes)
library(gridExtra)
library(ggbeeswarm)
library(corrplot)
library(ggcorrplot)
library(randomForest)
library(reshape2)
library(RColorBrewer)
```
## Download Data

```{r Dataset}
bc <- read.csv(url("https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data"), header = FALSE,
                   col.names = c("id", "diagnosis", "radius_mean", "texture_mean","perimeter_mean",          "area_mean","smoothness_mean","compactness_mean","concavity_mean","concave.points_mean","symmetry_mean", "fractal_dimension_mean","radius_se", "texture_se","perimeter_se","area_se","smoothness_se","compactness_se","concavity_se","concave.points_se","symmetry_se", "fractal_dimension_se", "radius_worst", "texture_worst","perimeter_worst", "area_worst","smoothness_worst","compactness_worst","concavity_worst","concave.points_worst","symmetry_worst", "fractal_dimension_worst" ))
```
# 3. Exploratory Data Analysis
Let's look at the structure of the data.
```{r EDA_1}
str(bc)
```

There are 569 observations with 32 variables. Variable id t contains id information which cannot be used in modeling.

Are there any NAs
```{r EDA_2}
bc %>% is.na() %>% sum()
```
Good, there are no NAs. Onward to more exploration and visualization to gain insights for modeling.

# 3.1 Diagnosis Variable
Let's explore the diagnosis variable first.
```{r EDA_3}
tab <- bc %>% 
  count(diagnosis) %>% 
  mutate(proportion = n/sum(n))
tab
```
The majority of the cases 357 (63%) are benign and 212 cases are malignant. We can plot this data as below.
```{r EDA_4}
tab %>% ggplot(aes(diagnosis, proportion)) + geom_bar(stat = "identity", fill = "grey") +
  theme_economist()
```
## 3.2 Nuclear Features {.tabset}
Next we explore the nuclear features.  We look at the distributions of the features using box plots.

### 1. radius

```{r EDA_5}
radius <- bc %>%
 select(c(diagnosis, radius_mean, radius_se, radius_worst)) %>%
 group_by(diagnosis) %>%
 summarise(Mean_radius_mean = mean(radius_mean), Mean_radius_se = mean(radius_se), Mean_radius_worst = mean(radius_worst))
radius
```


```{r EDA_6}
radius <- melt(bc,id.vars='diagnosis', measure.vars=c('radius_mean','radius_se','radius_worst'))

ggplot(radius, aes(x=diagnosis, y=value, fill=variable)) +
  geom_boxplot(alpha = 2/3) +
  labs(x = 'diagnosis') +
  theme_bw() + ggtitle("diagnosis x radius variables") +
  theme(plot.title = element_text(hjust = 0.5)) +
  facet_grid(~variable) +
  geom_jitter(alpha = I(1/4), aes(color = variable)) +
  stat_summary(fun.y=mean, geom="text", size=3, vjust=-3, aes( label=round(..y.., digits=2)))
```
The radius variable has higher values and spread in malignant cells. 

### 2. perimeter

```{r EDA_7}
perimeter <- bc %>%
 select(c(diagnosis, perimeter_mean, perimeter_se, perimeter_worst)) %>%
 group_by(diagnosis) %>%
 summarise(Mean_perimeter_mean = mean(perimeter_mean), Mean_perimeter_se = mean(perimeter_se), Mean_perimeter_worst = mean(perimeter_worst))
perimeter
```


```{r EDA_8}
per <- melt(bc,id.vars='diagnosis', measure.vars=c('perimeter_mean','perimeter_se','perimeter_worst'))

ggplot(per, aes(x=diagnosis, y=value, fill=variable)) +
  geom_boxplot(alpha = 2/3) +
  labs(x = 'diagnosis') +
  theme_bw() + ggtitle("diagnosis x perimeter variables") +
  theme(plot.title = element_text(hjust = 0.5)) +
  facet_grid(~variable) +
  geom_jitter(alpha = I(1/4), aes(color = variable)) +
  stat_summary(fun.y=mean, geom="text", size=3, vjust=-3, aes( label=round(..y.., digits=2)))
```
Perimeter of malignant cells is larger than of benign cells.

### 3. area

```{r EDA_9}
area <- bc %>%
 select(c(diagnosis, area_mean, area_se, area_worst)) %>%
 group_by(diagnosis) %>%
 summarise(Mean_area_mean = mean(area_mean), Mean_area_se = mean(area_se), Mean_area_worst = mean(area_worst))
area
```

```{r EDA_10}
area <- melt(bc,id.vars='diagnosis', measure.vars=c('area_mean','area_se','area_worst'))

ggplot(area, aes(x=diagnosis, y=value, fill=variable)) +
  geom_boxplot(alpha = 2/3) +
  labs(x = 'diagnosis') +
  theme_bw() + ggtitle("diagnosis x area variables") +
  theme(plot.title = element_text(hjust = 0.5)) +
  facet_grid(~variable) +
  geom_jitter(alpha = I(1/4), aes(color = variable)) +
  stat_summary(fun.y=mean, geom="text", size=3, vjust=-3, aes( label=round(..y.., digits=2)))
```
Area feature values are higher in malignant cells.  There is also higher variability in the malignant group.

### 4. concavity

```{r EDA_11}
concavity <- bc %>%
 select(c(diagnosis, concavity_mean, concavity_se, concavity_worst)) %>%
 group_by(diagnosis) %>%
 summarise(Mean_concavity_mean = mean(concavity_mean), Mean_concavity_se = mean(concavity_se), Mean_concavity_worst = mean(concavity_worst))
concavity
```


```{r EDA_12}
concavity <- melt(bc,id.vars='diagnosis', measure.vars=c('concavity_mean','concavity_se','concavity_worst'))

ggplot(concavity, aes(x=diagnosis, y=value, fill=variable)) +
  geom_boxplot(alpha = 2/3) +
  labs(x = 'diagnosis') +
  theme_bw() + ggtitle("diagnosis x concavity variables") +
  theme(plot.title = element_text(hjust = 0.5)) +
  facet_grid(~variable) +
  geom_jitter(alpha = I(1/4), aes(color = variable)) +
  stat_summary(fun.y=mean, geom="text", size=3, vjust=-3, aes( label=round(..y.., digits=2)))
```
Concavity variable values are higher in malignant cells. Group spread appears to be the same.

### 5. concave.points

```{r EDA_13}
concave.points <- bc %>%
 select(c(diagnosis, concave.points_mean, concave.points_se, concave.points_worst)) %>%
 group_by(diagnosis) %>%
 summarise(Mean_concave.points_mean = mean(concave.points_mean), Mean_concave.points_se = mean(concave.points_se), Mean_concave.points_worst = mean(concave.points_worst))
concave.points
```

```{r EDA_14}
con.points <- melt(bc,id.vars='diagnosis', measure.vars=c('concave.points_mean','concave.points_se','concave.points_worst'))

ggplot(con.points, aes(x=diagnosis, y=value, fill=variable)) +
  geom_boxplot(alpha = 2/3) +
  labs(x = 'diagnosis') +
  theme_bw() + ggtitle("diagnosis x radius variables") +
  theme(plot.title = element_text(hjust = 0.5)) +
  facet_grid(~variable) +
  geom_jitter(alpha = I(1/4), aes(color = variable)) +
  stat_summary(fun.y=mean, geom="text", size=3, vjust=-3, aes( label=round(..y.., digits=2)))
```
Higher values of concave points in malignant cells.

### 6.compactness

```{r EDA_15}
compactness <- bc %>%
 select(c(diagnosis, compactness_mean, compactness_se, compactness_worst)) %>%
 group_by(diagnosis) %>%
 summarise(Mean_compactness_mean = mean(compactness_mean), Mean_compactness_se = mean(compactness_se), Mean_compactness_worst = mean(compactness_worst))
compactness
```

```{r EDA_16}
compact <- melt(bc,id.vars='diagnosis', measure.vars=c('compactness_mean','compactness_se','compactness_worst'))

ggplot(compact, aes(x=diagnosis, y=value, fill=variable)) +
  geom_boxplot(alpha = 2/3) +
  labs(x = 'diagnosis') +
  theme_bw() + ggtitle("diagnosis x compactness variables") +
  theme(plot.title = element_text(hjust = 0.5)) +
  facet_grid(~variable) +
  geom_jitter(alpha = I(1/4), aes(color = variable)) +
  stat_summary(fun.y=mean, geom="text", size=3, vjust=-3, aes( label=round(..y.., digits=2)))
```
Moderately higher compactness values in malignant cells.

### 7. texture

```{r EDA_17}
texture <- bc %>%
 select(c(diagnosis, texture_mean, texture_se, texture_worst)) %>%
 group_by(diagnosis) %>%
 summarise(Mean_texture_mean = mean(texture_mean), Mean_texture_se = mean(texture_se), Mean_texture_worst = mean(texture_worst))
texture
```

```{r EDA_18}
texture <- melt(bc,id.vars='diagnosis', measure.vars=c('texture_mean','texture_se','texture_worst'))

ggplot(texture, aes(x=diagnosis, y=value, fill=variable)) +
  geom_boxplot(alpha = 2/3) +
  labs(x = 'diagnosis') +
  theme_bw() + ggtitle("diagnosis x texture variables") +
  theme(plot.title = element_text(hjust = 0.5)) +
  facet_grid(~variable) +
  geom_jitter(alpha = I(1/4), aes(color = variable)) +
  stat_summary(fun.y=mean, geom="text", size=3, vjust=-3, aes( label=round(..y.., digits=2)))
```
Moderately higher texture values in malignant cells.
### 8. smoothness

```{r EDA_19}
smoothness <- bc %>%
 select(c(diagnosis, smoothness_mean, smoothness_se, smoothness_worst)) %>%
 group_by(diagnosis) %>%
 summarise(Mean_smoothness_mean = mean(smoothness_mean), Mean_smoothness_se = mean(smoothness_se), Mean_smoothness_worst = mean(smoothness_worst))
smoothness
```

```{r EDA_20}
smooth <- melt(bc,id.vars='diagnosis', measure.vars=c('smoothness_mean','smoothness_se','smoothness_worst'))

ggplot(smooth, aes(x=diagnosis, y=value, fill=variable)) +
  geom_boxplot(alpha = 2/3) +
  labs(x = 'diagnosis') +
  theme_bw() + ggtitle("diagnosis x smoothness variables") +
  theme(plot.title = element_text(hjust = 0.5)) +
  facet_grid(~variable) +
  geom_jitter(alpha = I(1/4), aes(color = variable)) +
  stat_summary(fun.y=mean, geom="text", size=3, vjust=-3, aes( label=round(..y.., digits=2)))
```
Not much difference in the smoothness of cells from benign and malignant groups.

### 9.symmetry

```{r EDA_21}
symmetry <- bc %>%
 select(c(diagnosis, symmetry_mean, symmetry_se, symmetry_worst)) %>%
 group_by(diagnosis) %>%
 summarise(Mean_symmetry_mean = mean(symmetry_mean), Mean_symmetry_se = mean(symmetry_se), Mean_symmetry_worst = mean(symmetry_worst))
symmetry
```


```{r EDA_22}
symm <- melt(bc,id.vars='diagnosis', measure.vars=c('symmetry_mean','symmetry_se','symmetry_worst'))

ggplot(symm, aes(x=diagnosis, y=value, fill=variable)) +
  geom_boxplot(alpha = 2/3) +
  labs(x = 'diagnosis') +
  theme_bw() + ggtitle("diagnosis x symmetry variables") +
  theme(plot.title = element_text(hjust = 0.5)) +
  facet_grid(~variable) +
  geom_jitter(alpha = I(1/4), aes(color = variable)) +
  stat_summary(fun.y=mean, geom="text", size=3, vjust=-3, aes( label=round(..y.., digits=2)))
```
Symmetry feature is not very discriminatory.

### 10. fractal_dimension

```{r EDA_23}
fractal_dimension <- bc %>%
 select(c(diagnosis, fractal_dimension_mean, fractal_dimension_se, fractal_dimension_worst)) %>%
 group_by(diagnosis) %>%
 summarise(Mean_fractal_dimension_mean = mean(fractal_dimension_mean), Mean_fractal_dimension_se = mean(fractal_dimension_se), Mean_fractal_dimension_worst = mean(fractal_dimension_worst))
fractal_dimension
```



```{r EDA_24}
fract.dim <- melt(bc,id.vars='diagnosis', measure.vars=c('fractal_dimension_mean','fractal_dimension_se','fractal_dimension_worst'))

ggplot(fract.dim, aes(x=diagnosis, y=value, fill=variable)) +
  geom_boxplot(alpha = 2/3) +
  labs(x = 'diagnosis') +
  theme_bw() + ggtitle("diagnosis x fractical_dimension variables") +
  theme(plot.title = element_text(hjust = 0.5)) +
  facet_grid(~variable) +
  geom_jitter(alpha = I(1/4), aes(color = variable)) +
  stat_summary(fun.y=mean, geom="text", size=3, vjust=-3, aes( label=round(..y.., digits=2)))
```

Fractal_dimension values are almost the same between the two groups.
In summary the following features had higher values in malignant compared to benign cells:
1. radius
2. perimeter
3. area
4. concave_points
5. concavity



# 3.3 Correlation among Features
In the next section we are going to check the correlation between the variables.


```{r EDA_25}
bc.cor <- bc %>% select(-c(id, diagnosis))
corrplot(cor(bc.cor), type="lower", number.cex = .35, addCoef.col = "black", tl.col = "black", tl.srt = 90, tl.cex = .5, col=brewer.pal(n=8, name="RdPu"), order = "FPC")
```

There is very high correlation between some variables. Correlation indicates that there is redundancy in the data. PCA can be used to reduce the original variables into a smaller number of new variables (principal components) explaining most of the variance in the original variables.

# 4.Principal Component Analysis

```{r PCA}
pca <-prcomp(bc[,3:31], center=TRUE, scale=TRUE) 
summary(pca)
```
The first two components explain 62% of the variance. Below is a scree plot. The turning point in the level of explained variance indicates the number of principal components present in the data. In this case, there are 6, given the precipitous fall-off in the explained variance when moving from 6 to 7.

```{r PCA_2}
screeplot(pca, type ="lines")
```
Next we add diagnosis to see whether there is any separation between the malignant and benign groups.

```{r PCA_3}
data.frame(pca$x[,1:2], Diagnosis=bc$diagnosis) %>% 
  ggplot(aes(PC1,PC2, fill = Diagnosis))+
  geom_point(cex=3, pch=21) +
  coord_fixed(ratio = 1)

```
There are two distinct groups corresponding to malignant and benign groups. The malignant group has a lot of variability and spreads out.


# 5. Modeling and Predictions
# 5.1 Creating Train and Test Datasets
```{r Split_Data}
# Create train and test data sets
set.seed(125)
trainIndex <- createDataPartition(bc$diagnosis, p=0.8, list = FALSE)
trainData <- bc[trainIndex,]
testData <- bc[-trainIndex,]
```


```{r x_y}
x = trainData[,3:32]
y = trainData$diagnosis

```


# 5.2 Logistic Regression

```{r Mod_Log_PCA}
# Logistic Regression with PCA using the first six Principal Components
set.seed(125)
control <- trainControl(method="cv",
                        number = 5,
                        classProbs = TRUE,
                        preProcOptions = list(pcaComp = 6),
                        summaryFunction = twoClassSummary)
                        
model.log.pca <- train(diagnosis ~ ., trainData[,2:32],
                method="glm", metric = "ROC",
                preProcess = c("center", "scale", "pca"),
                trControl = control)

```

```{r Mod_Log_PCA_res}
pred.classes.log.pca <- predict(model.log.pca, testData)
results.log.pca <- confusionMatrix(pred.classes.log.pca, testData$diagnosis, positive = "M")
results.log.pca
```



# 5.3 KNN
```{r Mod_KNN}
# KNN Model with all Variables
set.seed(125)
control <- trainControl(method = "cv", number = 10, p = .9)
model.knn <- train(diagnosis ~ ., method = "knn", 
                   data = trainData[,2:32],
                   tuneGrid = data.frame(k = seq(6, 27, 3)),
                   trControl = control)
ggplot(model.knn, highlight = TRUE)

  
```
```{r Mod_KNN_res}
pred.classes.knn <- model.knn %>% predict(testData)
results.knn <- confusionMatrix(pred.classes.knn, testData$diagnosis, positive="M")
results.knn
```



```{r Mod_KNN_PCA}
# KNN model with PCA using the first 6 Principal Components
set.seed(125)
control <- trainControl(method="cv",
                        number = 10,
                        classProbs = TRUE,
                        preProcOptions = list(pcaComp = 6),
                        summaryFunction = twoClassSummary)
model.knn.pca <- train(diagnosis ~ ., trainData[,2:32],
                method="knn", metric = "ROC",
                preProcess = c("center", "scale", "pca"),
                trControl = control)
```



```{r Mod_KNN_PCA_res}
pred.classes.knn.pca <- model.knn.pca %>% predict(testData)
results.knn.pca <- confusionMatrix(pred.classes.knn.pca, testData$diagnosis, positive="M")
results.knn.pca
```
# 5.4 SVM with PCA using the first 6 Principal Components
```{r Log_SVM_PCA}
set.seed(125)
control <- trainControl(method="cv",
                        number = 10,
                        classProbs = TRUE,
                        preProcOptions = list(pcaComp = 6),
                        summaryFunction = twoClassSummary)
model.svm.pca <- train(diagnosis ~ ., trainData[,2:32],
                method="svmLinear", metric = "ROC",
                preProcess = c("center", "scale", "pca"),
                trControl = control)
```
```{r Log_SVM_PCA_res}
pred.classes.svm.pca <- model.svm.pca %>% predict(testData)
results.svm.pca <- confusionMatrix(pred.classes.svm.pca, testData$diagnosis, positive="M")
results.svm.pca
```
# 5.5 Random Forest

```{r Mod_RF}
# Random Forest Model (all variables)
set.seed(125)
control <- trainControl(method="cv", number = 5)
grid <- data.frame(mtry = c(1, 5, 10, 25))
model.rf <-  train(x, y, 
                   method = "rf", 
                   ntree = 150,
                   trControl = control,
                   tuneGrid = grid)
```


```{r Mod_RF_res}
pred.classes.rf <- model.rf %>% predict(testData)
results.rf <- confusionMatrix(pred.classes.rf, testData$diagnosis, positive = "M")
results.rf
```

```{r Mod_varIMp}
varImp(model.rf)
```

```{r Mod_RF_Top9}
# Random Forest Model (Top 9 variables most important)
set.seed(125)
control <- trainControl(method="cv", number = 5)
grid <- data.frame(mtry = c(1, 5, 7, 9))
model.rf2 <-  train(diagnosis ~ area_worst + perimeter_worst +  radius_worst + concave.points_worst + concave.points_mean + area_mean + perimeter_mean + concavity_mean + texture_worst, data = trainData,
                   method = "rf", 
                   ntree = 150,
                   trControl = control,
                   tuneGrid = grid)
```

```{r Mod_RF_Top9_res}
pred.classes.rf2 <- model.rf2 %>% predict(testData)
results.rf2 <- confusionMatrix(pred.classes.rf2, testData$diagnosis, positive = "M")
results.rf2
```


```{r Mod_RF_PCA}
# Random Forest Model using the first 6 Principal Components
set.seed(125)
control <- trainControl(method="cv", number = 5,  preProcOptions = list(pcaComp = 6))
grid <- data.frame(mtry = c(1, 3, 6))
model.rf.pca <-  train(x, y, 
                   method = "rf", 
                   ntree = 150,
                   preProcess = "pca",
                   trControl = control,
                   tuneGrid = grid)
```


```{r Mod_varIMp_PCA}
varImp(model.rf.pca)
```


```{r Mod_RF_PCA_res}
pred.classes.rf.pca <- model.rf.pca %>% predict(testData)
results.rf.pca <- confusionMatrix(pred.classes.rf.pca, testData$diagnosis, positive = "M")
results.rf.pca
```



```{r Mod_RF_4PCs}
# Random Forest Model using first 4 Principal Components.
set.seed(125)
control.4 <- trainControl(method="cv", number = 5,  preProcOptions = list(pcaComp = 4))
grid.4 <- data.frame(mtry = c(1, 2, 4))
model.rf.pca.2 <-  train(x, y, 
                   method = "rf", 
                   ntree = 150,
                   preProcess = "pca",
                   trControl = control.4,
                   tuneGrid = grid.4)
```

```{r Mod_RF_4PCs_res}
# Prediction PCA
pred.classes.pca.2 <- model.rf.pca.2 %>% predict(testData)
results.rf.pca.2 <- confusionMatrix(pred.classes.pca.2, testData$diagnosis, positive = "M")
results.rf.pca.2
```
# 6. Conclusion
```{r Conc}
#KNN
knn.1 <- as.data.frame(results.knn$overall["Accuracy"])
colnames(knn.1) <- ""
knn.2 <- as.data.frame(results.knn$byClass[1:4])
colnames(knn.2) <- ""
knn <- rbind(knn.1, knn.2)
colnames(knn) <- "KNN"

knn.pca1 <- as.data.frame(results.knn.pca$overall["Accuracy"])
colnames(knn.pca1) <- ""
knn.pca2 <- as.data.frame(results.knn.pca$byClass[1:4])
colnames(knn.pca2) <- ""
knn.pca <- rbind(knn.pca1, knn.pca2)
colnames(knn.pca) <- "KNN PCA"
row.names(knn.pca) <- c()

# Logistic Regression
log.pca1 <- as.data.frame(results.log.pca$overall["Accuracy"])
colnames(log.pca1) <- ""
log.pca2 <- as.data.frame(results.log.pca$byClass[1:4])
colnames(log.pca2) <- ""
log.pca <- rbind(log.pca1, log.pca2)
colnames(log.pca) <- "Logit PCA"
row.names(log.pca) <- c()

# SVM
svm.pca1 <- as.data.frame(results.svm.pca$overall["Accuracy"])
colnames(svm.pca1) <- ""
svm.pca2 <- as.data.frame(results.svm.pca$byClass[1:4])
colnames(svm.pca2) <- ""
svm.pca <- rbind(svm.pca1, svm.pca2)
colnames(svm.pca) <- "SVM PCA"
row.names(svm.pca) <- c()


#RF 
rf.1 <- as.data.frame(results.rf$overall["Accuracy"])
colnames(rf.1) <- ""
rf.2 <- as.data.frame(results.rf$byClass[1:4])
colnames(rf.2) <- ""
rf <- rbind(rf.1, rf.2)
colnames(rf) <- "RF"
row.names(rf) <- c()

rf2.1 <- as.data.frame(results.rf2$overall["Accuracy"])
colnames(rf2.1) <- ""
rf2.2 <- as.data.frame(results.rf2$byClass[1:4])
colnames(rf2.2) <- ""
rf2 <- rbind(rf2.1, rf2.2)
colnames(rf2) <- "RF (TOP 9)"
row.names(rf2) <- c()

rf.pca1 <- as.data.frame(results.rf.pca$overall["Accuracy"])
colnames(rf.pca1) <- ""
rf.pca2 <- as.data.frame(results.rf.pca$byClass[1:4])
colnames(rf.pca2) <- ""
rf.pca <- rbind(rf.pca1, rf.pca2)
colnames(rf.pca) <- "RF 6 PCs"
row.names(rf.pca) <- c()

rf.pca3 <- as.data.frame(results.rf.pca.2$overall["Accuracy"])
colnames(rf.pca3) <- ""
rf.pca4 <- as.data.frame(results.rf.pca.2$byClass[1:4])
colnames(rf.pca4) <- ""
rf.pca.2 <- rbind(rf.pca3, rf.pca4)
colnames(rf.pca.2) <- "RF 4 PCs"
row.names(rf.pca.2) <- c()


final <- as.data.frame(t(cbind(log.pca, knn, knn.pca, rf, rf2, rf.pca, rf.pca.2, svm.pca)))
```
```{r Final}
final
```
The logistic regression model with PCA pre-processing had the highest accuracy 97.3%, which is the ability of the model to correctly differentiate between malignant and benign. The random forest model without pre-processing or PCA prepocessing (first 4 PCs) achieved the second highest accuracy of 96.5%.

Sensitivity, is the ability of a model to correctly identify all patients with the disease. The logistic regression model with PCA processing had the highest sensitivity of 92.9%. High sensitivity makes a good screening test.

Specificity, is ability of the model to correctly identify those patients without the disease. All the models tested have very high specificity. High specificity makes a good confirmatory test.

Pos Pred Value is the percentage of patients with a positive test who actually have the disease (true positives), was 100% in all models except KNN model without PCA-preprocessing.

Neg Pred Value, which shows the percentage of patients with a negative test who do not have the disease (true negatives). The logistic regression model with PCA-preprocessing achieved the highest negative predictive value of 95.9%.

In general, the models performed with a range accuracy of 91.2% - 97.4% with very high specificity i.e correctly classify patients as disease-free (benign).
The following features seem to be important for the diagnosis of breast cancer using the FNA procedure :

perimeter_worst
concave_points_worst
area_worst
concave_points_mean
radius_worst


# 7. References

1. Kaggle, for the dataset https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/download
2. Kaggle Kernels on the dataset: https:www.kaggle.com
3. Course textbook: https://rafalab.github.io/dsbook/unix.html